{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis-TinyPointNet_tf2_VKITTI3D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMcHzZKx3obh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d146633-293a-4759-cc50-126a2d4efd76"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import h5py\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from time import time\n",
        "from datetime import timezone, datetime\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Reshape\n",
        "from keras.layers import Conv1D, SeparableConv1D, BatchNormalization, Dropout, GlobalMaxPooling1D, Layer\n",
        "from keras.layers import ReLU, Softmax\n",
        "from keras.layers import Lambda, Dot, Concatenate\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import RMSprop, Adam, SGD\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.initializers import Zeros, Constant\n",
        "from keras.regularizers import L2\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "print(f'TF_VERSION={tf.__version__}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF_VERSION=2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-n7-g3K6iDw"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "NUM_POINTS = 4096\n",
        "NUM_CLASSES = 13\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE=1e-3\n",
        "LR_DECAY_STEPS = 7000\n",
        "LR_DECAY_RATE = 0.7\n",
        "\n",
        "BASE_PATH='/content/gdrive/My Drive/Thesis/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqJeS2gWsXzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8038c5-656f-42df-d5f8-6303764724ad"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/gdrive/My Drive/Thesis/datasets/vkitti3d_h5.zip', 'r')\n",
        "zip_ref.extractall('/content/dataset')\n",
        "zip_ref.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXPTJTgUYUyC",
        "outputId": "2ab806ab-7b24-4251-9a57-c42ad6fa1641"
      },
      "source": [
        "train_data = []\n",
        "train_label = []\n",
        "\n",
        "files = glob.glob('/content/dataset/*')\n",
        "\n",
        "for file in files:\n",
        "    f = h5py.File(file, 'r')\n",
        "    train_data.append(f['normalized_points'][:, :, 0:3])\n",
        "    train_label.append(f['labels'])\n",
        "\n",
        "train_data = np.concatenate(train_data, axis=0)\n",
        "train_label = np.concatenate(train_label, axis=0)\n",
        "\n",
        "train_data, val_data, train_label, val_label = train_test_split(train_data, train_label, test_size=0.4, random_state=42)\n",
        "val_data, test_data, val_label, test_label = train_test_split(val_data, val_label, test_size=0.5, random_state=42)\n",
        "\n",
        "print(train_data.shape, train_label.shape)\n",
        "print(val_data.shape, val_label.shape)\n",
        "print(test_data.shape, test_label.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5058, 4096, 3) (5058, 4096)\n",
            "(1686, 4096, 3) (1686, 4096)\n",
            "(1686, 4096, 3) (1686, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70iC8L7kKz8p"
      },
      "source": [
        "def rotate(points):\n",
        "    theta = np.random.uniform((-np.pi / 8, np.pi / 8))\n",
        "    rotation_matrix = tf.stack([[tf.cos(theta), tf.sin(theta), 0],\n",
        "                                   [-tf.sin(theta), tf.cos(theta), 0],\n",
        "                                   [0, 0, 1]])\n",
        "    return tf.matmul(points, tf.cast(rotation_matrix, dtype=tf.float32))\n",
        "\n",
        "def augment(points, label):\n",
        "    # jitter points\n",
        "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float32)\n",
        "    # shuffle points\n",
        "    #points = tf.random.shuffle(points)\n",
        "    return points, label\n",
        "\n",
        "one_hot_train_label = np_utils.to_categorical(train_label, NUM_CLASSES)\n",
        "one_hot_val_label = np_utils.to_categorical(val_label, NUM_CLASSES)\n",
        "one_hot_test_label = np_utils.to_categorical(test_label, NUM_CLASSES)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, one_hot_train_label))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, one_hot_val_label))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, one_hot_test_label))\n",
        "\n",
        "#train_dataset = train_dataset.shuffle(len(train_data)).map(augment).batch(BATCH_SIZE, drop_remainder=True)\n",
        "train_dataset = train_dataset.repeat(6).shuffle(len(train_data)).map(augment).batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset = val_dataset.repeat(6).shuffle(len(val_data)).batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_dataset = test_dataset.repeat(6).shuffle(len(test_data)).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWB673hHbwca"
      },
      "source": [
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, num_features, l2_reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2_reg = l2_reg\n",
        "        self.eye = tf.eye(num_features)\n",
        "\n",
        "    def __call__(self, input):\n",
        "        input = tf.reshape(input, (-1, self.num_features, self.num_features))\n",
        "        xxt = tf.tensordot(input, input, axes=(2, 2))\n",
        "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return tf.reduce_sum(self.l2_reg * tf.square(xxt - self.eye))\n",
        "\n",
        "    #  Enable serialization\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'num_features': self.num_features,\n",
        "            'l2_reg': self.l2_reg\n",
        "        }\n",
        "    \n",
        "    # Enable deserialization\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13cACH23yIdL"
      },
      "source": [
        "class TNet(Layer):\n",
        "    def __init__(self, add_regularization=False, bn_momentum=0.99, **kwargs):\n",
        "        super(TNet, self).__init__(**kwargs)\n",
        "        self.add_regularization = add_regularization\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.conv0 = ConvLayer(16, 1, strides=1, bn_momentum=bn_momentum)\n",
        "        self.conv1 = ConvLayer(32, 1, strides=1, bn_momentum=bn_momentum)\n",
        "        #self.conv2 = ConvLayer(512, 1, strides=1, bn_momentum=bn_momentum)\n",
        "        self.conv2 = ConvLayer(256, 1, strides=1, bn_momentum=bn_momentum)\n",
        "        self.fc0 = DenseLayer(128, activation=tf.nn.relu, apply_bn=True, bn_momentum=bn_momentum)\n",
        "        self.fc1 = DenseLayer(64, activation=tf.nn.relu, apply_bn=True, bn_momentum=bn_momentum)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.K = input_shape[-1]\n",
        "\n",
        "        self.w = self.add_weight(shape=(64, self.K**2), initializer=tf.zeros_initializer,\n",
        "                                 trainable=True, name='w')\n",
        "        self.b = self.add_weight(shape=(self.K, self.K), initializer=tf.zeros_initializer,\n",
        "                                 trainable=True, name='b')\n",
        "\n",
        "        # Initialize bias with identity\n",
        "        I = tf.constant(np.eye(self.K), dtype=tf.float32)\n",
        "        self.b = tf.math.add(self.b, I)\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        input_x = x                                                     # BxNxK\n",
        "\n",
        "        # Embed to higher dim\n",
        "        x = tf.expand_dims(input_x, axis=2)                             # BxNx1xK\n",
        "        x = self.conv0(x, training=training)\n",
        "        x = self.conv1(x, training=training)\n",
        "        x = self.conv2(x, training=training)\n",
        "        x = tf.squeeze(x, axis=2)                                       # BxNx1024\n",
        "\n",
        "        # Global features\n",
        "        x = tf.reduce_max(x, axis=1)                                    # Bx1024\n",
        "\n",
        "        # Fully-connected layers\n",
        "        x = self.fc0(x, training=training)                              # Bx512\n",
        "        x = self.fc1(x, training=training)                              # Bx256\n",
        "\n",
        "        # Convert to KxK matrix to matmul with input\n",
        "        x = tf.expand_dims(x, axis=1)                                   # Bx1x256\n",
        "        x = tf.matmul(x, self.w)                                        # Bx1xK^2\n",
        "        x = tf.squeeze(x, axis=1)\n",
        "        x = tf.reshape(x, (-1, self.K, self.K))\n",
        "\n",
        "        # Add bias term (initialized to identity matrix)\n",
        "        x += self.b\n",
        "\n",
        "        # Add regularization\n",
        "        if self.add_regularization:\n",
        "            eye = tf.constant(np.eye(self.K), dtype=tf.float32)\n",
        "            x_xT = tf.matmul(x, tf.transpose(x, perm=[0, 2, 1]))\n",
        "            reg_loss = tf.nn.l2_loss(eye - x_xT)\n",
        "            self.add_loss(1e-3 * reg_loss)\n",
        "\n",
        "        return tf.matmul(input_x, x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TNet, self).get_config()\n",
        "        config.update({\n",
        "            'add_regularization': self.add_regularization,\n",
        "            'bn_momentum': self.bn_momentum})\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class ConvLayer(Layer):\n",
        "    def __init__(self, filters, kernel_size, strides, padding='valid', activation=None,\n",
        "                 apply_bn=False, bn_momentum=0.99, **kwargs):\n",
        "        super(ConvLayer, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.activation = activation\n",
        "        self.apply_bn = apply_bn\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.conv = Conv1D(filters, kernel_size, strides=strides, padding=padding,\n",
        "                           activation=activation, use_bias=not apply_bn)\n",
        "        if apply_bn:\n",
        "            self.bn = BatchNormalization(momentum=bn_momentum, fused=False)\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        x = self.conv(x)\n",
        "        if self.apply_bn:\n",
        "            x = self.bn(x, training=training)\n",
        "        if self.activation:\n",
        "            x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ConvLayer, self).get_config()\n",
        "        config.update({\n",
        "            'filters': self.filters,\n",
        "            'kernel_size': self.kernel_size,\n",
        "            'strides': self.strides,\n",
        "            'padding': self.padding,\n",
        "            'activation': self.activation,\n",
        "            'apply_bn': self.apply_bn,\n",
        "            'bn_momentum': self.bn_momentum})\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class DenseLayer(Layer):\n",
        "    def __init__(self, units, activation=None, apply_bn=False, bn_momentum=0.99, **kwargs):\n",
        "        super(DenseLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.apply_bn = apply_bn\n",
        "        self.bn_momentum = bn_momentum\n",
        "        self.dense = Dense(units, activation=activation, use_bias=not apply_bn)\n",
        "        if apply_bn:\n",
        "            self.bn = BatchNormalization(momentum=bn_momentum, fused=False)\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        x = self.dense(x)\n",
        "        if self.apply_bn:\n",
        "            x = self.bn(x, training=training)\n",
        "        if self.activation:\n",
        "            x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DenseLayer, self).get_config()\n",
        "        config.update({\n",
        "            'units': self.units,\n",
        "            'activation': self.activation,\n",
        "            'apply_bn': self.apply_bn,\n",
        "            'bn_momentum': self.bn_momentum})\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "def get_model(num_points, num_classes, bn_momentum=.99):\n",
        "    pt_cloud = Input(shape=(num_points, 3), dtype=tf.float32, name='pt_cloud')    # BxNx3\n",
        "\n",
        "    # Input transformer (B x N x 3 -> B x N x 3)\n",
        "    pt_cloud_transform = TNet(bn_momentum=bn_momentum)(pt_cloud)\n",
        "\n",
        "    # Embed to 64-dim space (B x N x 3 -> B x N x 32)\n",
        "    pt_cloud_transform = tf.expand_dims(pt_cloud_transform, axis=2)         # for weight-sharing of conv\n",
        "    hidden_32 = ConvLayer(32, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                           bn_momentum=bn_momentum)(pt_cloud_transform)\n",
        "    embed_32 = ConvLayer(32, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                          bn_momentum=bn_momentum)(hidden_32)\n",
        "    embed_32 = tf.squeeze(embed_32, axis=2)\n",
        "\n",
        "    # Feature transformer (B x N x 32 -> B x N x 32)\n",
        "    embed_32_transform_t = TNet(bn_momentum=bn_momentum, add_regularization=True)(embed_32)\n",
        "\n",
        "    # Embed to 256-dim space (B x N x 32 -> B x N x 256)\n",
        "    embed_32_transform = tf.expand_dims(embed_32_transform_t, axis=2)\n",
        "    hidden_32 = ConvLayer(32, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                           bn_momentum=bn_momentum)(embed_32_transform)\n",
        "    hidden_64 = ConvLayer(64, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                            bn_momentum=bn_momentum)(hidden_32)\n",
        "    #embed_1024 = ConvLayer(512, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "    #                        bn_momentum=bn_momentum)(hidden_128)\n",
        "    embed_256 = ConvLayer(256, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                            bn_momentum=bn_momentum)(hidden_64)\n",
        "    embed_256 = tf.squeeze(embed_256, axis=2)\n",
        "\n",
        "    # Global feature vector (B x N x 256 -> B x 256)\n",
        "    global_descriptor = tf.reduce_max(embed_256, axis=1)\n",
        "\n",
        "    global_descriptor = tf.expand_dims(global_descriptor, axis=1)\n",
        "\n",
        "    global_descriptor = tf.tile(global_descriptor, [1, num_points, 1])\n",
        "\n",
        "    # Segmentation block\n",
        "    concatenate = Concatenate()([embed_32_transform_t, global_descriptor])\n",
        "\n",
        "    hidden_128 = ConvLayer(128, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                           bn_momentum=bn_momentum)(concatenate)\n",
        "\n",
        "    hidden_128 = Dropout(rate=0.5)(hidden_128)\n",
        "\n",
        "    hidden_64 = ConvLayer(64, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                            bn_momentum=bn_momentum)(hidden_128)\n",
        "\n",
        "    hidden_64 = Dropout(rate=0.5)(hidden_64)\n",
        "    \n",
        "    embed_32 = ConvLayer(32, 1, strides=1, activation=tf.nn.relu, apply_bn=True,\n",
        "                            bn_momentum=bn_momentum)(hidden_64)\n",
        "\n",
        "    segmentation_output = Conv1D(filters=num_classes, kernel_size=1, strides=1, padding='valid')(embed_32)\n",
        "\n",
        "    logits = Softmax()(segmentation_output)\n",
        "\n",
        "    return Model(inputs=pt_cloud, outputs=logits, name='TinyPointNet_TF2-VKITTI3D')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x2c5tsOb9-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5f28ed-6f65-4894-8382-8e20980de781"
      },
      "source": [
        "model = get_model(num_points=NUM_POINTS, num_classes=NUM_CLASSES)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "metrics = [\n",
        "           'accuracy',\n",
        "           tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
        "]\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              #loss=anchor_loss,\n",
        "              metrics=metrics)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"TinyPointNet_TF2-VKITTI3D\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "pt_cloud (InputLayer)           [(None, 4096, 3)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "t_net_24 (TNet)                 (None, 4096, 3)      51360       pt_cloud[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_36 (Tens [(None, 4096, 1, 3)] 0           t_net_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_168 (ConvLayer)      (None, 4096, 1, 32)  224         tf_op_layer_ExpandDims_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_169 (ConvLayer)      (None, 4096, 1, 32)  1152        conv_layer_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_24 (TensorF [(None, 4096, 32)]   0           conv_layer_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "t_net_25 (TNet)                 (None, 4096, 32)     116784      tf_op_layer_Squeeze_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_37 (Tens [(None, 4096, 1, 32) 0           t_net_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_173 (ConvLayer)      (None, 4096, 1, 32)  1152        tf_op_layer_ExpandDims_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_174 (ConvLayer)      (None, 4096, 1, 64)  2304        conv_layer_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_175 (ConvLayer)      (None, 4096, 1, 256) 17408       conv_layer_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_25 (TensorF [(None, 4096, 256)]  0           conv_layer_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Max_12 (TensorFlowO [(None, 256)]        0           tf_op_layer_Squeeze_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_38 (Tens [(None, 1, 256)]     0           tf_op_layer_Max_12[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Tile_12 (TensorFlow [(None, 4096, 256)]  0           tf_op_layer_ExpandDims_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 4096, 288)    0           t_net_25[0][0]                   \n",
            "                                                                 tf_op_layer_Tile_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_176 (ConvLayer)      (None, 4096, 128)    37376       concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 4096, 128)    0           conv_layer_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_177 (ConvLayer)      (None, 4096, 64)     8448        dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 4096, 64)     0           conv_layer_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_layer_178 (ConvLayer)      (None, 4096, 32)     2176        dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_190 (Conv1D)             (None, 4096, 13)     429         conv_layer_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "softmax_11 (Softmax)            (None, 4096, 13)     0           conv1d_190[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 238,813\n",
            "Trainable params: 236,765\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0TxTyiLbliO"
      },
      "source": [
        "def decay_schedule(epoch, lr):\n",
        "    # decay LR every 10 epochs\n",
        "    if (epoch % 10 == 0) and (epoch != 0):\n",
        "        lr = lr / 2\n",
        "        print(f'Scheduled learning rate: {lr} on epoch {epoch}')\n",
        "    return lr\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=BASE_PATH + 'TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_{epoch:02d}-loss_{loss:.4f}-accuracy_{accuracy:.4f}.hdf5',\n",
        "    monitor='loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "earlystopping = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0,\n",
        "    verbose=1\n",
        ")\n",
        "    \n",
        "lr_scheduler = LearningRateScheduler(decay_schedule, verbose=1)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=BASE_PATH + 'TinyPointNet/Logs/2020-11-30-tiny-pointnet-vkitti3d')\n",
        "\n",
        "callbacks = [checkpoint, earlystopping, reduce_lr, lr_scheduler, tensorboard]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etDAF4lXoCpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23104a7f-ec2a-415e-94ef-42d686e014d7"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks,\n",
        "                    shuffle=True)\n",
        "\n",
        "model.save(BASE_PATH + 'TinyPointNet/TinyPointNet_keras-VKITTI3D-2020-11-30')\n",
        "model.save_weights(BASE_PATH + 'TinyPointNet/Weights/TinyPointNet-weights-final-VKITTI3D-2020-11-30.hdf5')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 1/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 1.3544 - accuracy: 0.5771 - mean_io_u_10: 0.4617\n",
            "Epoch 00001: loss improved from inf to 1.35443, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_01-loss_1.354-accuracy_0.577.hdf5\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 1.3544 - accuracy: 0.5771 - mean_io_u_10: 0.4617 - val_loss: 2.2774 - val_accuracy: 0.2172 - val_mean_io_u_10: 0.4615\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 2/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.8134 - mean_io_u_10: 0.4624\n",
            "Epoch 00002: loss improved from 1.35443 to 0.61974, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_02-loss_0.620-accuracy_0.813.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.6197 - accuracy: 0.8134 - mean_io_u_10: 0.4624 - val_loss: 1.5604 - val_accuracy: 0.5777 - val_mean_io_u_10: 0.4616\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 3/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8678 - mean_io_u_10: 0.4631\n",
            "Epoch 00003: loss improved from 0.61974 to 0.44261, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_03-loss_0.443-accuracy_0.868.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.4426 - accuracy: 0.8678 - mean_io_u_10: 0.4631 - val_loss: 226.0509 - val_accuracy: 0.4296 - val_mean_io_u_10: 0.4633\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 4/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.8929 - mean_io_u_10: 0.4645\n",
            "Epoch 00004: loss improved from 0.44261 to 0.36037, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_04-loss_0.360-accuracy_0.893.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.3604 - accuracy: 0.8929 - mean_io_u_10: 0.4645 - val_loss: 0.4667 - val_accuracy: 0.8528 - val_mean_io_u_10: 0.4617\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 5/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.9037 - mean_io_u_10: 0.4666\n",
            "Epoch 00005: loss improved from 0.36037 to 0.32289, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_05-loss_0.323-accuracy_0.904.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.3229 - accuracy: 0.9037 - mean_io_u_10: 0.4666 - val_loss: 0.3881 - val_accuracy: 0.8851 - val_mean_io_u_10: 0.4672\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 6/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.9122 - mean_io_u_10: 0.4687\n",
            "Epoch 00006: loss improved from 0.32289 to 0.29446, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_06-loss_0.294-accuracy_0.912.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.2945 - accuracy: 0.9122 - mean_io_u_10: 0.4687 - val_loss: 0.2586 - val_accuracy: 0.9155 - val_mean_io_u_10: 0.4637\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 7/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9180 - mean_io_u_10: 0.4710\n",
            "Epoch 00007: loss improved from 0.29446 to 0.27453, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_07-loss_0.275-accuracy_0.918.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.2745 - accuracy: 0.9180 - mean_io_u_10: 0.4710 - val_loss: 0.2139 - val_accuracy: 0.9265 - val_mean_io_u_10: 0.4652\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 8/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.9223 - mean_io_u_10: 0.4729\n",
            "Epoch 00008: loss improved from 0.27453 to 0.25744, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_08-loss_0.257-accuracy_0.922.hdf5\n",
            "474/474 [==============================] - 295s 623ms/step - loss: 0.2574 - accuracy: 0.9223 - mean_io_u_10: 0.4729 - val_loss: 0.2426 - val_accuracy: 0.9177 - val_mean_io_u_10: 0.4695\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 9/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.9249 - mean_io_u_10: 0.4744\n",
            "Epoch 00009: loss improved from 0.25744 to 0.24827, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_09-loss_0.248-accuracy_0.925.hdf5\n",
            "474/474 [==============================] - 295s 623ms/step - loss: 0.2483 - accuracy: 0.9249 - mean_io_u_10: 0.4744 - val_loss: 0.2282 - val_accuracy: 0.9194 - val_mean_io_u_10: 0.4649\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 10/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.9092 - mean_io_u_10: 0.4732\n",
            "Epoch 00010: loss did not improve from 0.24827\n",
            "474/474 [==============================] - 295s 622ms/step - loss: 0.3014 - accuracy: 0.9092 - mean_io_u_10: 0.4732 - val_loss: 0.3958 - val_accuracy: 0.8815 - val_mean_io_u_10: 0.4635\n",
            "Scheduled learning rate: 0.0005000000237487257 on epoch 10\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 11/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9294 - mean_io_u_10: 0.4741\n",
            "Epoch 00011: loss improved from 0.24827 to 0.23218, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_11-loss_0.232-accuracy_0.929.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.2322 - accuracy: 0.9294 - mean_io_u_10: 0.4741 - val_loss: 0.1833 - val_accuracy: 0.9362 - val_mean_io_u_10: 0.4647\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 12/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9323 - mean_io_u_10: 0.4762\n",
            "Epoch 00012: loss improved from 0.23218 to 0.22171, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_12-loss_0.222-accuracy_0.932.hdf5\n",
            "474/474 [==============================] - 295s 623ms/step - loss: 0.2217 - accuracy: 0.9323 - mean_io_u_10: 0.4762 - val_loss: 0.1864 - val_accuracy: 0.9334 - val_mean_io_u_10: 0.4674\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 13/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9343 - mean_io_u_10: 0.4779\n",
            "Epoch 00013: loss improved from 0.22171 to 0.21462, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_13-loss_0.215-accuracy_0.934.hdf5\n",
            "474/474 [==============================] - 295s 623ms/step - loss: 0.2146 - accuracy: 0.9343 - mean_io_u_10: 0.4779 - val_loss: 0.1666 - val_accuracy: 0.9426 - val_mean_io_u_10: 0.4685\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 14/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9357 - mean_io_u_10: 0.4796\n",
            "Epoch 00014: loss improved from 0.21462 to 0.20959, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_14-loss_0.210-accuracy_0.936.hdf5\n",
            "474/474 [==============================] - 295s 622ms/step - loss: 0.2096 - accuracy: 0.9357 - mean_io_u_10: 0.4796 - val_loss: 0.1614 - val_accuracy: 0.9432 - val_mean_io_u_10: 0.4711\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 15/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9373 - mean_io_u_10: 0.4813\n",
            "Epoch 00015: loss improved from 0.20959 to 0.20392, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_15-loss_0.204-accuracy_0.937.hdf5\n",
            "474/474 [==============================] - 295s 622ms/step - loss: 0.2039 - accuracy: 0.9373 - mean_io_u_10: 0.4813 - val_loss: 0.1448 - val_accuracy: 0.9501 - val_mean_io_u_10: 0.4719\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 16/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9379 - mean_io_u_10: 0.4828\n",
            "Epoch 00016: loss improved from 0.20392 to 0.20189, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_16-loss_0.202-accuracy_0.938.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.2019 - accuracy: 0.9379 - mean_io_u_10: 0.4828 - val_loss: 0.1819 - val_accuracy: 0.9363 - val_mean_io_u_10: 0.4721\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 17/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9389 - mean_io_u_10: 0.4839\n",
            "Epoch 00017: loss improved from 0.20189 to 0.19837, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_17-loss_0.198-accuracy_0.939.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1984 - accuracy: 0.9389 - mean_io_u_10: 0.4839 - val_loss: 0.1433 - val_accuracy: 0.9506 - val_mean_io_u_10: 0.4786\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 18/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.9406 - mean_io_u_10: 0.4857\n",
            "Epoch 00018: loss improved from 0.19837 to 0.19229, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_18-loss_0.192-accuracy_0.941.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1923 - accuracy: 0.9406 - mean_io_u_10: 0.4857 - val_loss: 0.1372 - val_accuracy: 0.9525 - val_mean_io_u_10: 0.4719\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 19/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9409 - mean_io_u_10: 0.4871\n",
            "Epoch 00019: loss improved from 0.19229 to 0.19136, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_19-loss_0.191-accuracy_0.941.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1914 - accuracy: 0.9409 - mean_io_u_10: 0.4871 - val_loss: 0.2049 - val_accuracy: 0.9353 - val_mean_io_u_10: 0.4712\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 20/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9414 - mean_io_u_10: 0.4878\n",
            "Epoch 00020: loss improved from 0.19136 to 0.18985, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_20-loss_0.190-accuracy_0.941.hdf5\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1898 - accuracy: 0.9414 - mean_io_u_10: 0.4878 - val_loss: 0.1346 - val_accuracy: 0.9537 - val_mean_io_u_10: 0.4782\n",
            "Scheduled learning rate: 0.0002500000118743628 on epoch 20\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 21/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9443 - mean_io_u_10: 0.4894\n",
            "Epoch 00021: loss improved from 0.18985 to 0.18022, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_21-loss_0.180-accuracy_0.944.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1802 - accuracy: 0.9443 - mean_io_u_10: 0.4894 - val_loss: 0.1234 - val_accuracy: 0.9567 - val_mean_io_u_10: 0.4800\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 22/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9454 - mean_io_u_10: 0.4904\n",
            "Epoch 00022: loss improved from 0.18022 to 0.17638, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_22-loss_0.176-accuracy_0.945.hdf5\n",
            "474/474 [==============================] - 298s 629ms/step - loss: 0.1764 - accuracy: 0.9454 - mean_io_u_10: 0.4904 - val_loss: 0.1221 - val_accuracy: 0.9564 - val_mean_io_u_10: 0.4813\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 23/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9454 - mean_io_u_10: 0.4915\n",
            "Epoch 00023: loss improved from 0.17638 to 0.17614, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_23-loss_0.176-accuracy_0.945.hdf5\n",
            "474/474 [==============================] - 298s 628ms/step - loss: 0.1761 - accuracy: 0.9454 - mean_io_u_10: 0.4915 - val_loss: 0.1268 - val_accuracy: 0.9560 - val_mean_io_u_10: 0.4781\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 24/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9455 - mean_io_u_10: 0.4924\n",
            "Epoch 00024: loss improved from 0.17614 to 0.17568, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_24-loss_0.176-accuracy_0.946.hdf5\n",
            "474/474 [==============================] - 298s 628ms/step - loss: 0.1757 - accuracy: 0.9455 - mean_io_u_10: 0.4924 - val_loss: 0.1406 - val_accuracy: 0.9490 - val_mean_io_u_10: 0.4802\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 25/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9460 - mean_io_u_10: 0.4931\n",
            "Epoch 00025: loss improved from 0.17568 to 0.17389, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_25-loss_0.174-accuracy_0.946.hdf5\n",
            "474/474 [==============================] - 298s 628ms/step - loss: 0.1739 - accuracy: 0.9460 - mean_io_u_10: 0.4931 - val_loss: 0.1208 - val_accuracy: 0.9571 - val_mean_io_u_10: 0.4852\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 26/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.9467 - mean_io_u_10: 0.4940\n",
            "Epoch 00026: loss improved from 0.17389 to 0.17164, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_26-loss_0.172-accuracy_0.947.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1716 - accuracy: 0.9467 - mean_io_u_10: 0.4940 - val_loss: 0.1212 - val_accuracy: 0.9572 - val_mean_io_u_10: 0.4805\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 27/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9472 - mean_io_u_10: 0.4948\n",
            "Epoch 00027: loss improved from 0.17164 to 0.17000, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_27-loss_0.170-accuracy_0.947.hdf5\n",
            "474/474 [==============================] - 296s 625ms/step - loss: 0.1700 - accuracy: 0.9472 - mean_io_u_10: 0.4948 - val_loss: 0.1183 - val_accuracy: 0.9590 - val_mean_io_u_10: 0.4826\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 28/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9474 - mean_io_u_10: 0.4956\n",
            "Epoch 00028: loss improved from 0.17000 to 0.16889, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_28-loss_0.169-accuracy_0.947.hdf5\n",
            "474/474 [==============================] - 296s 625ms/step - loss: 0.1689 - accuracy: 0.9474 - mean_io_u_10: 0.4956 - val_loss: 0.1164 - val_accuracy: 0.9594 - val_mean_io_u_10: 0.4817\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 29/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9470 - mean_io_u_10: 0.4961\n",
            "Epoch 00029: loss did not improve from 0.16889\n",
            "474/474 [==============================] - 296s 625ms/step - loss: 0.1705 - accuracy: 0.9470 - mean_io_u_10: 0.4961 - val_loss: 0.1161 - val_accuracy: 0.9589 - val_mean_io_u_10: 0.4815\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 30/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.9480 - mean_io_u_10: 0.4967\n",
            "Epoch 00030: loss improved from 0.16889 to 0.16698, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_30-loss_0.167-accuracy_0.948.hdf5\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.1670 - accuracy: 0.9480 - mean_io_u_10: 0.4967 - val_loss: 0.1221 - val_accuracy: 0.9558 - val_mean_io_u_10: 0.4829\n",
            "Scheduled learning rate: 0.0001250000059371814 on epoch 30\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 31/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9493 - mean_io_u_10: 0.4976\n",
            "Epoch 00031: loss improved from 0.16698 to 0.16274, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_31-loss_0.163-accuracy_0.949.hdf5\n",
            "474/474 [==============================] - 296s 625ms/step - loss: 0.1627 - accuracy: 0.9493 - mean_io_u_10: 0.4976 - val_loss: 0.1087 - val_accuracy: 0.9628 - val_mean_io_u_10: 0.4810\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 32/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9488 - mean_io_u_10: 0.4979\n",
            "Epoch 00032: loss did not improve from 0.16274\n",
            "474/474 [==============================] - 295s 623ms/step - loss: 0.1647 - accuracy: 0.9488 - mean_io_u_10: 0.4979 - val_loss: 0.1117 - val_accuracy: 0.9612 - val_mean_io_u_10: 0.4849\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 33/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9494 - mean_io_u_10: 0.4984\n",
            "Epoch 00033: loss did not improve from 0.16274\n",
            "474/474 [==============================] - 296s 624ms/step - loss: 0.1628 - accuracy: 0.9494 - mean_io_u_10: 0.4984 - val_loss: 0.1104 - val_accuracy: 0.9613 - val_mean_io_u_10: 0.4837\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 34/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9499 - mean_io_u_10: 0.4988\n",
            "Epoch 00034: loss improved from 0.16274 to 0.16090, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_34-loss_0.161-accuracy_0.950.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1609 - accuracy: 0.9499 - mean_io_u_10: 0.4988 - val_loss: 0.1067 - val_accuracy: 0.9630 - val_mean_io_u_10: 0.4824\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 35/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9497 - mean_io_u_10: 0.4992\n",
            "Epoch 00035: loss did not improve from 0.16090\n",
            "474/474 [==============================] - 296s 625ms/step - loss: 0.1616 - accuracy: 0.9497 - mean_io_u_10: 0.4992 - val_loss: 0.1091 - val_accuracy: 0.9619 - val_mean_io_u_10: 0.4859\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 36/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9501 - mean_io_u_10: 0.4995\n",
            "Epoch 00036: loss improved from 0.16090 to 0.15999, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_36-loss_0.160-accuracy_0.950.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1600 - accuracy: 0.9501 - mean_io_u_10: 0.4995 - val_loss: 0.1076 - val_accuracy: 0.9619 - val_mean_io_u_10: 0.4856\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 37/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9500 - mean_io_u_10: 0.4999\n",
            "Epoch 00037: loss did not improve from 0.15999\n",
            "474/474 [==============================] - 298s 628ms/step - loss: 0.1604 - accuracy: 0.9500 - mean_io_u_10: 0.4999 - val_loss: 0.1127 - val_accuracy: 0.9607 - val_mean_io_u_10: 0.4852\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 38/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9503 - mean_io_u_10: 0.5005\n",
            "Epoch 00038: loss improved from 0.15999 to 0.15931, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_38-loss_0.159-accuracy_0.950.hdf5\n",
            "474/474 [==============================] - 297s 628ms/step - loss: 0.1593 - accuracy: 0.9503 - mean_io_u_10: 0.5005 - val_loss: 0.1109 - val_accuracy: 0.9609 - val_mean_io_u_10: 0.4858\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 39/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9503 - mean_io_u_10: 0.5009\n",
            "Epoch 00039: loss did not improve from 0.15931\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.5000001187436283e-05.\n",
            "474/474 [==============================] - 297s 628ms/step - loss: 0.1593 - accuracy: 0.9503 - mean_io_u_10: 0.5009 - val_loss: 0.1070 - val_accuracy: 0.9630 - val_mean_io_u_10: 0.4925\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to 2.5000001187436283e-05.\n",
            "Epoch 40/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9510 - mean_io_u_10: 0.5010\n",
            "Epoch 00040: loss improved from 0.15931 to 0.15746, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_40-loss_0.157-accuracy_0.951.hdf5\n",
            "474/474 [==============================] - 297s 628ms/step - loss: 0.1575 - accuracy: 0.9510 - mean_io_u_10: 0.5010 - val_loss: 0.1049 - val_accuracy: 0.9633 - val_mean_io_u_10: 0.4862\n",
            "Scheduled learning rate: 1.2500000593718141e-05 on epoch 40\n",
            "\n",
            "Epoch 00041: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 41/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9516 - mean_io_u_10: 0.5010\n",
            "Epoch 00041: loss improved from 0.15746 to 0.15538, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_41-loss_0.155-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1554 - accuracy: 0.9516 - mean_io_u_10: 0.5010 - val_loss: 0.1026 - val_accuracy: 0.9642 - val_mean_io_u_10: 0.4865\n",
            "\n",
            "Epoch 00042: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 42/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9517 - mean_io_u_10: 0.5011\n",
            "Epoch 00042: loss improved from 0.15538 to 0.15507, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_42-loss_0.155-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 628ms/step - loss: 0.1551 - accuracy: 0.9517 - mean_io_u_10: 0.5011 - val_loss: 0.1024 - val_accuracy: 0.9643 - val_mean_io_u_10: 0.4859\n",
            "\n",
            "Epoch 00043: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 43/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9518 - mean_io_u_10: 0.5013\n",
            "Epoch 00043: loss improved from 0.15507 to 0.15481, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_43-loss_0.155-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1548 - accuracy: 0.9518 - mean_io_u_10: 0.5013 - val_loss: 0.1029 - val_accuracy: 0.9639 - val_mean_io_u_10: 0.4863\n",
            "\n",
            "Epoch 00044: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 44/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9518 - mean_io_u_10: 0.5014\n",
            "Epoch 00044: loss improved from 0.15481 to 0.15467, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_44-loss_0.155-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1547 - accuracy: 0.9518 - mean_io_u_10: 0.5014 - val_loss: 0.1024 - val_accuracy: 0.9640 - val_mean_io_u_10: 0.4865\n",
            "\n",
            "Epoch 00045: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 45/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9519 - mean_io_u_10: 0.5014\n",
            "Epoch 00045: loss improved from 0.15467 to 0.15443, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_45-loss_0.154-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 298s 628ms/step - loss: 0.1544 - accuracy: 0.9519 - mean_io_u_10: 0.5014 - val_loss: 0.1022 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4870\n",
            "\n",
            "Epoch 00046: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 46/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9518 - mean_io_u_10: 0.5014\n",
            "Epoch 00046: loss did not improve from 0.15443\n",
            "474/474 [==============================] - 298s 628ms/step - loss: 0.1549 - accuracy: 0.9518 - mean_io_u_10: 0.5014 - val_loss: 0.1019 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4870\n",
            "\n",
            "Epoch 00047: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 47/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9520 - mean_io_u_10: 0.5016\n",
            "Epoch 00047: loss improved from 0.15443 to 0.15426, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_47-loss_0.154-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1543 - accuracy: 0.9520 - mean_io_u_10: 0.5016 - val_loss: 0.1023 - val_accuracy: 0.9643 - val_mean_io_u_10: 0.4866\n",
            "\n",
            "Epoch 00048: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 48/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9520 - mean_io_u_10: 0.5016\n",
            "Epoch 00048: loss improved from 0.15426 to 0.15402, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_48-loss_0.154-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1540 - accuracy: 0.9520 - mean_io_u_10: 0.5016 - val_loss: 0.1019 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4867\n",
            "\n",
            "Epoch 00049: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 49/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9518 - mean_io_u_10: 0.5015\n",
            "Epoch 00049: loss did not improve from 0.15402\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1545 - accuracy: 0.9518 - mean_io_u_10: 0.5015 - val_loss: 0.1021 - val_accuracy: 0.9641 - val_mean_io_u_10: 0.4869\n",
            "\n",
            "Epoch 00050: LearningRateScheduler reducing learning rate to 1.2500000593718141e-05.\n",
            "Epoch 50/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9518 - mean_io_u_10: 0.5018\n",
            "Epoch 00050: loss did not improve from 0.15402\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "474/474 [==============================] - 297s 628ms/step - loss: 0.1547 - accuracy: 0.9518 - mean_io_u_10: 0.5018 - val_loss: 0.1024 - val_accuracy: 0.9640 - val_mean_io_u_10: 0.4870\n",
            "Scheduled learning rate: 1.2500000821091817e-06 on epoch 50\n",
            "\n",
            "Epoch 00051: LearningRateScheduler reducing learning rate to 1.2500000821091817e-06.\n",
            "Epoch 51/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9522 - mean_io_u_10: 0.5018\n",
            "Epoch 00051: loss improved from 0.15402 to 0.15340, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_51-loss_0.153-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1534 - accuracy: 0.9522 - mean_io_u_10: 0.5018 - val_loss: 0.1018 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4868\n",
            "\n",
            "Epoch 00052: LearningRateScheduler reducing learning rate to 1.2500000821091817e-06.\n",
            "Epoch 52/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9520 - mean_io_u_10: 0.5018\n",
            "Epoch 00052: loss did not improve from 0.15340\n",
            "474/474 [==============================] - 296s 625ms/step - loss: 0.1541 - accuracy: 0.9520 - mean_io_u_10: 0.5018 - val_loss: 0.1019 - val_accuracy: 0.9643 - val_mean_io_u_10: 0.4869\n",
            "\n",
            "Epoch 00053: LearningRateScheduler reducing learning rate to 1.2500000821091817e-06.\n",
            "Epoch 53/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9520 - mean_io_u_10: 0.5017\n",
            "Epoch 00053: loss did not improve from 0.15340\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1539 - accuracy: 0.9520 - mean_io_u_10: 0.5017 - val_loss: 0.1017 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4868\n",
            "\n",
            "Epoch 00054: LearningRateScheduler reducing learning rate to 1.2500000821091817e-06.\n",
            "Epoch 54/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9523 - mean_io_u_10: 0.5017\n",
            "Epoch 00054: loss improved from 0.15340 to 0.15302, saving model to /content/gdrive/My Drive/Thesis/TinyPointNet/Weights/TinyPointNet-weights-VKITTI3D-2020-11-30-epoch_54-loss_0.153-accuracy_0.952.hdf5\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1530 - accuracy: 0.9523 - mean_io_u_10: 0.5017 - val_loss: 0.1017 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4866\n",
            "\n",
            "Epoch 00055: LearningRateScheduler reducing learning rate to 1.2500000821091817e-06.\n",
            "Epoch 55/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9520 - mean_io_u_10: 0.5017\n",
            "Epoch 00055: loss did not improve from 0.15302\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.500000164218363e-07.\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1540 - accuracy: 0.9520 - mean_io_u_10: 0.5017 - val_loss: 0.1017 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4867\n",
            "\n",
            "Epoch 00056: LearningRateScheduler reducing learning rate to 2.500000277905201e-07.\n",
            "Epoch 56/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9520 - mean_io_u_10: 0.5018\n",
            "Epoch 00056: loss did not improve from 0.15302\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1541 - accuracy: 0.9520 - mean_io_u_10: 0.5018 - val_loss: 0.1018 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4867\n",
            "\n",
            "Epoch 00057: LearningRateScheduler reducing learning rate to 2.500000277905201e-07.\n",
            "Epoch 57/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9521 - mean_io_u_10: 0.5017\n",
            "Epoch 00057: loss did not improve from 0.15302\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1537 - accuracy: 0.9521 - mean_io_u_10: 0.5017 - val_loss: 0.1017 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4868\n",
            "\n",
            "Epoch 00058: LearningRateScheduler reducing learning rate to 2.500000277905201e-07.\n",
            "Epoch 58/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9521 - mean_io_u_10: 0.5018\n",
            "Epoch 00058: loss did not improve from 0.15302\n",
            "474/474 [==============================] - 297s 626ms/step - loss: 0.1538 - accuracy: 0.9521 - mean_io_u_10: 0.5018 - val_loss: 0.1015 - val_accuracy: 0.9646 - val_mean_io_u_10: 0.4868\n",
            "\n",
            "Epoch 00059: LearningRateScheduler reducing learning rate to 2.500000277905201e-07.\n",
            "Epoch 59/100\n",
            "474/474 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9519 - mean_io_u_10: 0.5018\n",
            "Epoch 00059: loss did not improve from 0.15302\n",
            "474/474 [==============================] - 297s 627ms/step - loss: 0.1543 - accuracy: 0.9519 - mean_io_u_10: 0.5018 - val_loss: 0.1016 - val_accuracy: 0.9644 - val_mean_io_u_10: 0.4869\n",
            "Epoch 00059: early stopping\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/Thesis/TinyPointNet/TinyPointNet_keras-VKITTI3D-2020-11-30/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXwNx3GRhBfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "1a24bfa8-7142-4940-c34b-a4792d36f7fa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax4tEsgadnjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba9c6ec-41ee-47ac-877a-0ccaaacefd7d"
      },
      "source": [
        "loss, acc, _ = model.evaluate(test_data, one_hot_test_label)\n",
        "print(f'Test loss: {loss}')\n",
        "print(f'Test accuracy: {acc}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 3s 54ms/step - loss: 0.0997 - accuracy: 0.9647 - mean_io_u_10: 0.4884\n",
            "Test loss: 0.09967906773090363\n",
            "Test accuracy: 0.9646637439727783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMX0fGLLDQPs",
        "outputId": "c11aa46e-230a-4802-b4ea-18a4d8fc17f2"
      },
      "source": [
        "for filename in files:\n",
        "    f = h5py.File(filename, 'r')\n",
        "\n",
        "    points = f['points']\n",
        "    norm_points = f['normalized_points']\n",
        "    labels = f['labels']\n",
        "\n",
        "    data = norm_points[:, :, 0:3]\n",
        "\n",
        "    predictions = model.predict(data)\n",
        "    \n",
        "    print(f'file: {filename} - shape: {predictions.shape}')\n",
        "\n",
        "    pred_filename = BASE_PATH + 'TinyPointNet/Predictions-VKITTI3D/' + 'predictions_' + filename.split(\"/\")[-1]\n",
        "\n",
        "    pf = h5py.File(pred_filename, 'w')\n",
        "    pf.create_dataset('points', data=points, compression='gzip', dtype='float32')\n",
        "    pf.create_dataset('normalized_points', data=norm_points, compression='gzip', dtype='float32')\n",
        "    pf.create_dataset('predicted_points', data=predictions, compression='gzip', dtype='float32')\n",
        "    pf.create_dataset('labels', data=labels, compression='gzip', dtype='int64')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file: /content/dataset/vkitti3d_h5_v10018_00250.h5 - shape: (104, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00140.h5 - shape: (102, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00121.h5 - shape: (106, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00143.h5 - shape: (86, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00079.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00418.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00671.h5 - shape: (107, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00210.h5 - shape: (84, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00223.h5 - shape: (86, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00145.h5 - shape: (99, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00406.h5 - shape: (91, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00288.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00262.h5 - shape: (84, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00338.h5 - shape: (91, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00085.h5 - shape: (94, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00015.h5 - shape: (99, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00243.h5 - shape: (90, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00170.h5 - shape: (103, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00030.h5 - shape: (105, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00500.h5 - shape: (92, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00095.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00158.h5 - shape: (80, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00184.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00338.h5 - shape: (105, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00585.h5 - shape: (84, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00420.h5 - shape: (91, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00270.h5 - shape: (96, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00325.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00297.h5 - shape: (99, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00379.h5 - shape: (88, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00365.h5 - shape: (91, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00228.h5 - shape: (104, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00012.h5 - shape: (90, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00607.h5 - shape: (78, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00106.h5 - shape: (81, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00340.h5 - shape: (84, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00157.h5 - shape: (99, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00392.h5 - shape: (91, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00714.h5 - shape: (91, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00118.h5 - shape: (103, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00628.h5 - shape: (84, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00133.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00366.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00024.h5 - shape: (100, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00184.h5 - shape: (82, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00074.h5 - shape: (104, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00052.h5 - shape: (105, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00207.h5 - shape: (86, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00236.h5 - shape: (84, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00735.h5 - shape: (88, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00542.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00000.h5 - shape: (103, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00294.h5 - shape: (104, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00191.h5 - shape: (86, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00444.h5 - shape: (89, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00132.h5 - shape: (81, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00031.h5 - shape: (98, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00311.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00392.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00650.h5 - shape: (105, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00060.h5 - shape: (107, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00314.h5 - shape: (102, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00063.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00109.h5 - shape: (104, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00097.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00352.h5 - shape: (93, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00206.h5 - shape: (104, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00757.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00111.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00284.h5 - shape: (93, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00072.h5 - shape: (107, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00800.h5 - shape: (79, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00162.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00047.h5 - shape: (92, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00692.h5 - shape: (95, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00564.h5 - shape: (85, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00175.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00159.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00272.h5 - shape: (105, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00080.h5 - shape: (81, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10002_00127.h5 - shape: (87, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00257.h5 - shape: (94, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00230.h5 - shape: (96, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00096.h5 - shape: (103, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00000.h5 - shape: (97, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00778.h5 - shape: (80, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10020_00521.h5 - shape: (99, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00048.h5 - shape: (101, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10018_00316.h5 - shape: (105, 4096, 13)\n",
            "file: /content/dataset/vkitti3d_h5_v10001_00036.h5 - shape: (106, 4096, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-f-053gihgy",
        "outputId": "974c5a0a-9b1e-4ecb-a7b1-14401f3858ec"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "logdir = '/content/gdrive/My Drive/Thesis/TinyPointNet/Logs/2020-11-30-tiny-pointnet-vkitti3d'\n",
        "\n",
        "!ls '/content/gdrive/My Drive/Thesis/TinyPointNet/Logs/2020-11-30-tiny-pointnet-vkitti3d'\n",
        "\n",
        "%tensorboard --logdir '/content/gdrive/My Drive/Thesis/TinyPointNet/Logs/2020-11-30-tiny-pointnet-vkitti3d'"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "train  validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6007 (pid 2383), started 0:11:41 ago. (Use '!kill 2383' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6007, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgbTuruj3x5l"
      },
      "source": [
        "def anchor_loss(y_true, y_pred, gamma=0.5):\n",
        "    pred_prob = tf.math.sigmoid(y_pred)\n",
        "\n",
        "    # Obtain probabilities at indices of true class\n",
        "    true_mask = tf.dtypes.cast(y_true, dtype=tf.bool)\n",
        "    q_star = tf.boolean_mask(pred_prob, true_mask)\n",
        "    q_star = tf.expand_dims(q_star, axis=1)\n",
        "\n",
        "    # Calculate bce and add anchor loss coeff where labels equal 0\n",
        "    loss_bce = tf.nn.sigmoid_cross_entropy_with_logits(y_true, y_pred)\n",
        "    M = 1.0 - y_true\n",
        "    loss_calc = (M * (1.0 + pred_prob - q_star + 0.05)**gamma + (1.0 - M)) * loss_bce\n",
        "\n",
        "    return tf.math.reduce_mean(loss_calc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI3w_AFKMPFU"
      },
      "source": [
        "# Create model\n",
        "def get_bn_momentum(step):\n",
        "    return min(0.99, 0.5 + 0.0002*step)\n",
        "\n",
        "print('Creating PointNet model...')\n",
        "\n",
        "bn_momentum = tf.Variable(get_bn_momentum(0), trainable=False, name='momentum')\n",
        "print(bn_momentum)\n",
        "model = get_model(num_points=NUM_POINTS, num_classes=NUM_CLASSES, bn_momentum=bn_momentum)\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHUcqFZNMflG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6105fe86-46de-45b7-adad-58b525785b30"
      },
      "source": [
        "# Instantiate optimizer and loss function\n",
        "def get_lr(initial_learning_rate, decay_steps, decay_rate, step, staircase=False, warm_up=True):\n",
        "    if warm_up:\n",
        "        coeff1 = min(1.0, step/2000)\n",
        "    else:\n",
        "        coeff1 = 1.0\n",
        "\n",
        "    if staircase:\n",
        "        coeff2 = decay_rate ** (step // decay_steps)\n",
        "    else:\n",
        "        coeff2 = decay_rate ** (step / decay_steps)\n",
        "\n",
        "    current = initial_learning_rate * coeff1 * coeff2\n",
        "    return current\n",
        "LR_ARGS = {'initial_learning_rate': LEARNING_RATE, 'decay_steps': LR_DECAY_STEPS,\n",
        "           'decay_rate': LR_DECAY_RATE, 'staircase': False, 'warm_up': True}\n",
        "lr = tf.Variable(get_lr(**LR_ARGS, step=0), trainable=False, name='learning_rate')\n",
        "print(lr)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss_fxn = tf.keras.losses.categorical_crossentropy\n",
        "\n",
        "\n",
        "# Instantiate metric objects\n",
        "train_acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "train_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
        "train_prec = tf.keras.metrics.Precision()\n",
        "train_recall = tf.keras.metrics.Recall()\n",
        "val_acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
        "val_prec = tf.keras.metrics.Precision()\n",
        "val_recall = tf.keras.metrics.Recall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0LMtqBMthq"
      },
      "source": [
        "# Training\n",
        "print('Training...')\n",
        "print(f'Steps per epoch = {len(train_data) // BATCH_SIZE}')\n",
        "print(f'Total steps = {(len(train_data) // BATCH_SIZE) * EPOCHS}')\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "    # Forward pass with gradient tape and loss calc\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(inputs, training=True)\n",
        "        loss = loss_fxn(labels, logits) + sum(model.losses)\n",
        "\n",
        "    # Obtain gradients of trainable vars w.r.t. loss and perform update\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    return logits, loss, model.losses[0]\n",
        "\n",
        "\n",
        "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir_base = BASE_PATH + '/logs/pointnet-tf2/'\n",
        "train_log_dir = log_dir_base + current_time + '/train'\n",
        "test_log_dir = log_dir_base + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir_base)\n",
        "tensorboard_callback.set_model(model)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def val_step(inputs, labels):\n",
        "    logits = model(inputs, training=False)\n",
        "    loss = loss_fxn(labels, logits)\n",
        "    return logits, loss\n",
        "\n",
        "step = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    # print(f'Epoch: {epoch}')\n",
        "\n",
        "    # Reset metrics\n",
        "    train_acc.reset_states()\n",
        "    train_loss.reset_states()\n",
        "    train_prec.reset_states()\n",
        "    train_recall.reset_states()\n",
        "    val_acc.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    val_prec.reset_states()\n",
        "    val_recall.reset_states()\n",
        "\n",
        "    # Train on batches\n",
        "    for x_train, y_train in train_dataset:\n",
        "        tic = time()\n",
        "\n",
        "        logits, loss, mat_reg_loss = train_step(x_train, y_train)\n",
        "\n",
        "        train_probs = tf.math.sigmoid(logits)\n",
        "        train_acc.update_state(y_train, train_probs)\n",
        "        train_loss.update_state(loss)\n",
        "\n",
        "        max_idxs = tf.math.argmax(train_probs, axis=2)\n",
        "        train_one_hot = tf.one_hot(max_idxs, depth=NUM_CLASSES, dtype=tf.float32)\n",
        "        train_prec.update_state(y_train, train_one_hot)\n",
        "        train_recall.update_state(y_train, train_one_hot)\n",
        "\n",
        "        '''\n",
        "        print(f'time_per_step: {time() - tic}')\n",
        "        print(f'learning_rate: {lr.numpy()}')\n",
        "        print(f'training_loss: {train_loss.numpy()}')\n",
        "        print(f'mat_reg_loss: {mat_reg_loss.numpy()}')\n",
        "        print(f'bn_momentum: {bn_momentum.numpy()}')\n",
        "        '''\n",
        "        \n",
        "        step += 1\n",
        "        bn_momentum.assign(get_bn_momentum(step))\n",
        "        lr.assign(get_lr(**LR_ARGS, step=step))\n",
        "    \n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', train_acc.result(), step=epoch)\n",
        "\n",
        "    # Run validation at the end of epoch\n",
        "    for x_val, y_val in test_dataset:\n",
        "        logits, loss = val_step(x_val, y_val)\n",
        "\n",
        "        val_probs = tf.math.sigmoid(logits)\n",
        "        val_acc.update_state(y_val, val_probs)\n",
        "        val_loss.update_state(loss)\n",
        "\n",
        "        max_idxs = tf.math.argmax(val_probs, axis=2)\n",
        "        val_one_hot = tf.one_hot(max_idxs, depth=NUM_CLASSES, dtype=tf.float32)\n",
        "        val_prec.update_state(y_val, val_one_hot)\n",
        "        val_recall.update_state(y_val, val_one_hot)\n",
        "\n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', val_loss.result(), step=epoch)\n",
        "        tf.summary.scalar('accuracy', val_acc.result(), step=epoch)\n",
        "\n",
        "    # Save every epoch (.save_weights() since bn_momentum instance isn't serializable)\n",
        "    print(f'Save weights at step {step}')\n",
        "    model.save_weights(BASE_PATH + f'weights/pointnet-tf2-weights-SIS3D-epoch-{epoch}-{datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}', save_format='h5')\n",
        "\n",
        "    #print(f'train accuracy: {train_acc.result().numpy()}')\n",
        "    #print(f'train precision: {train_prec.result().numpy()}')\n",
        "    #print(f'train recall: {train_recall.result().numpy()}')\n",
        "    #print(f'val accuracy: {val_acc.result().numpy()}')\n",
        "    #print(f'val precision: {val_prec.result().numpy()}')\n",
        "    #print(f'val recall: {val_recall.result().numpy()}')\n",
        "\n",
        "    print(f'Epoch: {epoch+1} - loss: {train_loss.result():.4f} accuracy: {train_acc.result():.4f} val_loss: {val_loss.result():.4f} val_accuracy: {val_acc.result():.4f}')\n",
        "\n",
        "#print('Done training! Save model...')\n",
        "#model.save(BASE_PATH + f'pointnet-tf2-model-SIS3D-{datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}-accuracy-{val_acc.result():.4f}', save_format='tf')\n",
        "#print('Model saved successfully!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}